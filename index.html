<!DOCTYPE HTML>

<head>
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  
  <style type="text/css">
  /* Design Credits: Jon Barron, Deepak Pathak and Saurabh Gupta*/
  a {
  color: #1772d0;
  text-decoration:none;
  }
  a:focus, a:hover {
  color: #f09228;
  text-decoration:none;
  }
  body,td,th {
     font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
     font-size: 14px;
     font-weight: 400
  }
  heading {
     font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
     font-size: 22px;
     font-weight: 1000
  }
  papertitle {
  font-family: 'Lato', Verdana, Helvetica, sans-serif;
  font-size: 14px;
  font-weight: 500;
  color: blue
  }

  strong {
     font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
     font-size: 14px;
     font-weight: 800
  }
  strongred {
     font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
     color: 'red' ;
     font-size: 14px;
     font-weight: 800
  }
  sectionheading {
     font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
     font-size: 22px;
     font-weight: 600
  }
  pageheading {
     font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
     font-size: 36px;
     font-weight: 400
  }
  </style>

  <link rel="icon" type="image/jpeg" href="images/uds_logo.jpeg">
  <script type="text/javascript" src="js/hidebib.js"></script>
  <title>Soumava Paul</title>
  <meta name="Soumava's Homepage" http-equiv="Content-Type" content="Soumava's Homepage">
  <link href='https://fonts.googleapis.com/css?family=Titillium+Web:400,600,400italic,600italic,300,300italic' rel='stylesheet' type='text/css'>
  <!-- <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css"> -->
  <link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/all.min.css integrity="sha256-+N4/V/SbAFiW1MPBCXnfnP9QSN3+Keu+NlB+0ev/YKQ=" crossorigin=anonymous>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <!-- <link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin=anonymous> -->

  <!-- Scramble Script by Jeff Donahue -->
  <script src="js/scramble.js"></script>

</head>

<body>
  <table width="840" border="0" align="center" border="0" cellspacing="0" cellpadding="20">
    <tr><td>

      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <p align="center">
          <pageheading>Soumava Paul</pageheading><br>
          <b>email</b>:
          <font id="email" style="display:inline;">
              <noscript><i>Please enable Javascript to view</i></noscript>
          </font>
          <script>
          emailScramble = new scrambledString(document.getElementById('email'),
                'emailScramble', 'soumava2016@gmail.com',
                [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21]);
          </script>
        </p>

        <td style="padding:2.5%;width:63%;vertical-align:middle">
          <p>Hi, visitor! This is Soumava and you have reached my small corner on the World Wide Web. I am a Master's student in 
            <a href="https://www.mia.uni-saarland.de/mvc/index.shtml" target="_blank">Visual Computing</a> at 
            <a href="https://www.uni-saarland.de/" target="_blank">Universität des Saarlandes</a> and a research assistant at the 
            <a href="https://www.mpi-inf.mpg.de/departments/computer-vision-and-machine-learning" target="_blank">Max-Planck-Institut für Informatik</a>.
            Currently, I am working on sparse-view 3D reconstruction of unbounded scenes for my Master's thesis with 
            <a href="https://janericlenssen.github.io/" target="_blank">Dr. Jan Eric Lenssen</a> and 
            <a href="https://www.mpi-inf.mpg.de/departments/computer-vision-and-machine-learning/people/bernt-schiele" target="_blank">Prof. Bernt Schiele</a>. 
          </p>
          <p> Before coming to Germany, I was a data scientist at 
            <a href="https://www.hp.com/in-en/hp-labs/research/overview.html" target="_blank">HP Inc India</a> where I worked with 
            <a href="https://scholar.google.ca/citations?user=daDIHuUAAAAJ&hl=en" target="_blank">Niranjan Damera Venkata</a> on time series forecasting problems in finance. 
            I have also spent time as a Research Fellow at <a href="https://iisc.ac.in/" target="_blank">Indian Institute of Science, Bangalore</a>, working with 
            <a href="https://sites.google.com/iisc.ac.in/somabiswas" target="_blank">Prof. Soma Biswas</a> on problems at the intersection of cross-modal retrieval 
            and domain generalization.
          </p>
          <p> Previously, I graduated from <a href="http://www.iitkgp.ac.in" target="_blank">Indian Institute of Technology Kharagpur</a> with a bachelor's degree in 
            Electrical Engineering and a minor in Computer Science. I was fortunate enough to be advised by 
            <a href="https://cse.iitkgp.ac.in/~ksrao/" target="_blank">Prof. K. Sreenivasa Rao</a> for my bachelor's thesis on Singing Voice Detection. During my undergrad, I
            interned at <a href="https://research.ibm.com/labs/india" target="_blank">IBM India Research Labs, Bangalore</a> where I worked on novel zero-shot learning algorithms.
          </p>

          <p style="text-align:center">
            <a style="margin: 0 15px 0 0" href="data/CV_web.pdf" target="_blank"><i class="ai ai-cv" style="font-size:1.3rem"></i></a>
            <a style="margin: 0 15px 0 0" href="https://github.com/mvp18" target="_blank"><i class="fab fa-github"  style="font-size:1.3rem"></i></a>
            <a style="margin: 0 15px 0 0" href="https://scholar.google.com/citations?user=DK7mUVEAAAAJ&hl=en" target="_blank">
              <i class="ai ai-google-scholar" style="font-size:1.3rem"></i></a>
            <a style="margin: 0 15px 0 0" href="https://www.linkedin.com/in/mvp18/" target="_blank"><i class="fab fa-linkedin" style="font-size:1.3rem"></i></a>
            <a style="margin: 0 0 0 0" href="https://twitter.com/__mvp18__" target="_blank"><i class="fab fa-twitter" style="font-size:1.3rem"></i></a>
          </p>
        </td>
        <td style="padding:2.5%;width:40%;max-width:40%">
          <a href="images/profile_pic(1).jpeg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/profile_pic(1)-circle.jpg" class="hoverZoomLink"></a>
        </td></tr>
      
      </table>

      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr><td style="padding:10px;width:100%;vertical-align:middle">
            <sectionheading>News</sectionheading>
            <ul>
              <li><strong>[April 2022]</strong>&nbsp; Started my Master's at Universität des Saarlandes.</li>
              <li><strong>[August 2021]</strong>&nbsp; Two papers accepted to <a href="https://iccv2021.thecvf.com/" target="_blank">ICCV 2021</a>! 1 main track and 1 workshop.</li>
              <li><strong>[June 2021]</strong>&nbsp; One paper on singing voice detection accepted to <a href="https://www.interspeech2021.org/" target="_blank">Interspeech 2021</a>!</li>
              <li><strong>[May 2020]</strong>&nbsp; Graduated from IIT Kharagpur after 4 wonderful years.</li>
              <li><strong>[December 2018]</strong>&nbsp; Presented my first research paper at <a href="https://cvit.iiit.ac.in/icvgip18/">ICVGIP 2018</a> held at IIIT Hyderabad.</li>
              <li><strong>[July 2016]</strong>&nbsp; Started my journey at IIT Kharagpur as an undergrad.</li>
            </ul>
        </td></tr>
      </tbody></table>
        
      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr><td style="padding:10px;width:100%;vertical-align:middle">
            <heading>Research</heading>
            <p>
              Broadly, I am interested in computer vision, music information retrieval, and time series forecasting. Below are some of my representative publications. <!-- Representative papers are <span class="highlight">highlighted</span>. -->
            </p>
          </td>
        </tr>
      </tbody></table>

      <div><em>* denotes equal contribution</em></div>

      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr>
          <td style="padding:20px;width:25%;vertical-align:middle">
            <img src="pubs/fig_rotation_snmpnet.png" width=300 height=170 style="border-style: none">
          </td>
            <td width="67%" valign="top">
              <papertitle>Test-time Training for Data-efficient UCDR</papertitle><br>
              <strong>Soumava Paul</strong>,
              <a href="https://dblp.org/pid/214/9199.html" target="_blank">Titir Dutta</a>,
              Aheli Saha,
              Abhishek Samanta,
              <a href="https://scholar.google.com/citations?user=xtgxW9gAAAAJ&hl=en" target="_blank">Soma Biswas</a>
              <br>
              <em>arXiv preprint</em>
              <br>

                <div class="paper" id="ttt-ucdr">
                <a href="javascript:toggleblock('ttt-ucdrabs')"><font color="red">abstract</font></a> / 
                <a shape="rect" href="javascript:togglebib('ttt-ucdr')" class="togglebib"><font color="red">bibtex</font></a> / 
                <a href="https://arxiv.org/abs/2208.09198" target="_blank"><font color="red">arXiv</font></a> /
                <a href="https://github.com/mvp18/TTT-UCDR" target="_blank"><font color="red">Code</font></a> 
                <br>

                <p align="justify"> <i id="ttt-ucdrabs">Image retrieval under generalized test scenarios has gained significant momentum in literature, and the 
                recently proposed protocol of Universal Cross-domain Retrieval is a pioneer in this direction. A common practice in any such generalized 
                classification or retrieval algorithm is to exploit samples from many domains during training to learn a domain-invariant representation of data. 
                Such criterion is often restrictive, and thus in this work, for the first time, we explore the generalized retrieval problem in a data-efficient 
                manner. Specifically, we aim to generalize any pre-trained cross-domain retrieval network towards any unknown query domain/category, by means of 
                adapting the model on the test data leveraging self-supervised learning techniques. Toward that goal, we explored different self-supervised loss 
                functions~(for example, RotNet, JigSaw, Barlow Twins, etc.) and analyze their effectiveness for the same. Extensive experiments demonstrate the 
                proposed approach is simple, easy to implement, and effective in handling data-efficient UCDR.</i></p>

      <pre xml:space="preserve">
      @misc{paul2023testtime,
        title={Test-time Training for Data-efficient UCDR}, 
        author={Soumava Paul and Titir Dutta and Aheli Saha and Abhishek Samanta and Soma Biswas},
        year={2023},
        eprint={2208.09198},
        archivePrefix={arXiv},
        primaryClass={cs.CV}
      }
      }</pre>
                </div>
            </td>
        </tr>
      </table>


      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr>
          <td style="padding:20px;width:25%;vertical-align:middle">
            <img src="pubs/snmpnet.jpg" width=300 height=170 style="border-style: none">
          </td>
            <td width="67%" valign="top">
              <papertitle>Universal Cross-Domain Retrieval: Generalizing Across Classes and Domains</papertitle><br>
              <strong>Soumava Paul*</strong>,
              <a href="https://dblp.org/pid/214/9199.html" target="_blank">Titir Dutta</a>*,
              <a href="https://scholar.google.com/citations?user=xtgxW9gAAAAJ&hl=en" target="_blank">Soma Biswas</a>
              <br>
              <em>ICCV 2021</em>
              <br>

                <div class="paper" id="ucdr">
                <a href="javascript:toggleblock('ucdrabs')"><font color="red">abstract</font></a> / 
                <a shape="rect" href="javascript:togglebib('ucdr')" class="togglebib"><font color="red">bibtex</font></a> / 
                <a href="https://openaccess.thecvf.com/content/ICCV2021/html/Paul_Universal_Cross-Domain_Retrieval_Generalizing_Across_Classes_and_Domains_ICCV_2021_paper.html" target="_blank"><font color="red">proceedings</font></a> /
                <a href="http://arxiv.org/abs/2108.08356" target="_blank"><font color="red">arXiv</font></a> / 
                <a href="https://github.com/mvp18/UCDR" target="_blank"><font color="red">Code</font></a> / Video / 
                <a href="pubs/ucdr_video_slides.pptx"><font color="red">slides</font></a> / 
                <a href="pubs/ucdr_iccv21_poster.pdf"><font color="red">poster</font></a>
                <br>

                <p align="justify"> <i id="ucdrabs">In this work, for the first time, we address the problem of universal cross-domain retrieval, where the test data 
                can belong to classes or domains which are unseen during training. Due to dynamically increasing number of categories and practical constraint of 
                training on every possible domain, which requires large amounts of data, generalizing to both unseen classes and domains is important. Towards that 
                goal, we propose SnMpNet (Semantic Neighbourhood and Mixture Prediction Network), which incorporates two novel losses to account for the unseen 
                classes and domains encountered during testing. Specifically, we introduce a novel Semantic Neighborhood loss to bridge the knowledge gap between 
                seen and unseen classes and ensure that the latent space embedding of the unseen classes is semantically meaningful with respect to its neighboring 
                classes. We also introduce a mix-up based supervision at image-level as well as semantic-level of the data for training with the Mixture Prediction 
                loss, which helps in efficient retrieval when the query belongs to an unseen domain. These losses are incorporated on the SE-ResNet50 backbone to 
                obtain SnMpNet. Extensive experiments on two large-scale datasets, Sketchy Extended and DomainNet, and thorough comparisons with state-of-the-art 
                justify the effectiveness of the proposed model.</i></p>

      <pre xml:space="preserve">
      @InProceedings{Paul_2021_ICCV,
        author    = {Paul, Soumava and Dutta, Titir and Biswas, Soma},
        title     = {Universal Cross-Domain Retrieval: Generalizing Across Classes and Domains},
        booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
        month     = {October},
        year      = {2021},
        pages     = {12056-12064}
      }
      }</pre>
                </div>
            </td>
        </tr>
      </table>


      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr>
          <td style="padding:20px;width:25%;vertical-align:middle">
            <img src="pubs/spec.png" width=300 height=200 style="border-style: none">
          </td>
            <td width="67%" valign="top">
              <papertitle>Knowledge Distillation for Singing Voice Detection</papertitle><br>
              <strong>Soumava Paul</strong>,
              <a href="https://scholar.google.com/citations?user=WuqsazcAAAAJ&hl=en" target="_blank">Gurunath Reddy M</a>,
              <a href="https://scholar.google.co.in/citations?user=TATEL2EAAAAJ&hl=en" target="_blank">K. Sreenivasa Rao</a>,
              <a href="https://scholar.google.com/citations?user=RmjEzGMAAAAJ&hl=en" target="_blank">PP Das</a>
              <br>
              <em>INTERSPEECH 2021</em>
              <br>

                <div class="paper" id="kdsvd">
                <a href="javascript:toggleblock('kdsvdabs')"><font color="red">abstract</font></a> / 
                <a shape="rect" href="javascript:togglebib('kdsvd')" class="togglebib"><font color="red">bibtex</font></a> / 
                <a href="https://www.isca-speech.org/archive/interspeech_2021/paul21b_interspeech.html" target="_blank"><font color="red">proceedings</font></a> /
                <a href="https://arxiv.org/abs/2011.04297" target="_blank"><font color="red">arXiv</font></a> / 
                <a href="https://github.com/mvp18/KD-SVD" target="_blank"><font color="red">Code</font></a> / 
                <a href="https://www.youtube.com/watch?v=pCATYEGmwuQ"><font color="red">Video</font></a> /
                <a href="pubs/KD_SVD_15min.pptx"><font color="red">slides</font></a>
                <br>

                <p align="justify"> <i id="kdsvdabs">Singing Voice Detection (SVD) has been an active area of research in music information retrieval (MIR). 
                Currently, two deep neural network-based methods, one based on CNN and the other on RNN, exist in literature that learn optimized features for 
                the voice detection (VD) task and achieve state-of-the-art performance on common datasets. Both these models have a huge number of 
                parameters (1.4M for CNN and 65.7K for RNN) and hence not suitable for deployment on devices like smartphones or embedded sensors with limited 
                capacity in terms of memory and computation power. The most popular method to address this issue is known as knowledge distillation in deep learning 
                literature (in addition to model compression) where a large pre-trained network known as the teacher is used to train a smaller student network. 
                Given the wide applications of SVD in music information retrieval, to the best of our knowledge, model compression for practical deployment has not 
                yet been explored. In this paper, efforts have been made to investigate this issue using both conventional as well as ensemble knowledge distillation 
                techniques.</i></p>

      <pre xml:space="preserve">
      @inproceedings{paul21b_interspeech,
        author={Soumava Paul and Gurunath Reddy M and K. Sreenivasa Rao and Partha Pratim Das},
        title={{Knowledge Distillation for Singing Voice Detection}},
        year=2021,
        booktitle={Proc. Interspeech 2021},
        pages={4159--4163},
        doi={10.21437/Interspeech.2021-636}
      }
      }</pre>
                </div>
            </td>
        </tr>
      </table>

      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr>
          <td style="padding:20px;width:25%;vertical-align:middle">
            <img src="pubs/cheetah.png" width=300 height=264 style="border-style: none">
          </td>
            <td width="67%" valign="top">
              <papertitle>Addressing Target Shift in Zero-shot Learning using Grouped Adversarial Learning</papertitle><br>
              <a href="https://scholar.google.co.in/citations?user=FZ4YVdcAAAAJ&hl=en" target="_blank">Saneem Ahmed Chemmengath*</a>,
              <strong>Soumava Paul*</strong>,
              <a href="https://scholar.google.co.in/citations?user=zEnqhxkAAAAJ&hl=en" target="_blank">Samarth Bharadwaj</a>,
              <a href="https://scholar.google.co.in/citations?user=kB9KbxUAAAAJ&hl=en" target="_blank">Suranjana Samanta</a>,
              <a href="https://scholar.google.com/citations?user=vXDP-uEAAAAJ&hl=en" target="_blank">Karthik Sankaranarayanan</a>
              <br>
              <em>ICCV 2021 MELEX Workshop</em> &nbsp <font color="red">(Oral)</font>
              <br>

                <div class="paper" id="gAL">
                <a href="javascript:toggleblock('gALabs')"><font color="red">abstract</font></a> / 
                <a shape="rect" href="javascript:togglebib('gAL')" class="togglebib"><font color="red">bibtex</font></a> / 
                <a href="https://openaccess.thecvf.com/content/ICCV2021W/MELEX/html/Chemmengath_Addressing_Target_Shift_in_Zero-Shot_Learning_Using_Grouped_Adversarial_Learning_ICCVW_2021_paper.html" target="_blank"><font color="red">proceedings</font></a> /
                <a href="https://arxiv.org/abs/2003.00845" target="_blank"><font color="red">arXiv</font></a> / 
                <a href="https://github.com/mvp18/gAL-MELEX" target="_blank"><font color="red">Code</font></a> / 
                <a href="https://youtu.be/HPj074xLK0A"><font color="red">Video</font></a>
                <br>

                <p align="justify"> <i id="gALabs">Zero-shot learning (ZSL) algorithms typically work by exploiting attribute correlations to make predictions for 
                unseen classes. However, these correlations do not remain intact at test time in most practical settings, and the resulting change in these 
                correlations leads to adverse effects on zero-shot learning performance. In this paper, we present a new paradigm for ZSL that: (i) utilizes the 
                class-attribute mapping of unseen classes to estimate the change in target distribution (target shift), and (ii) propose a novel technique called 
                grouped Adversarial Learning (gAL) to reduce negative effects of this shift. Our approach is widely applicable for several existing ZSL algorithms, 
                including those with implicit attribute predictions. We apply the proposed technique (gAL) on three popular ZSL algorithms: ALE, SJE, and DEVISE, 
                and show performance improvements on 4 popular ZSL datasets: AwA2, aPY, CUB, and SUN.</i></p>

      <pre xml:space="preserve">
      @InProceedings{Chemmengath_2021_ICCV,
        author    = {Chemmengath, Saneem A. and Paul, Soumava and Bharadwaj, Samarth and Samanta, Suranjana and Sankaranarayanan, Karthik},
        title     = {Addressing Target Shift in Zero-Shot Learning Using Grouped Adversarial Learning},
        booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV) Workshops},
        month     = {October},
        year      = {2021},
        pages     = {2368-2377}
      }
      }</pre>
                </div>
            </td>
        </tr>
      </table>

      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr>
          <td style="padding:20px;width:25%;vertical-align:middle">
            <img src="pubs/3234AE-CNN__00015400_001_heatmap.png" width=300 height=264 style="border-style: none">
          </td>
            <td width="67%" valign="top">
              <papertitle>Jointly Learning Convolutional Representations to Compress Radiological Images and Classify Thoracic Diseases in the Compressed Domain</papertitle><br>
              Ekagra Ranjan*, <strong>Soumava Paul*</strong>, Siddharth Kapoor, 
              <a href="https://scholar.google.com/citations?hl=en&authuser=1&user=4ignEUcAAAAJ" target="_blank">Aupendu Kar</a>, 
              <a href="https://scholar.google.com/citations?user=hFUdp_EAAAAJ&hl=en" target="_blank">Ramanathan Sethuraman</a>,
              <a href="https://scholar.google.com/citations?user=x-0vLSsAAAAJ&hl=en" target="_blank">Debdoot Sheet</a>
              <br>
              <a href="https://cvit.iiit.ac.in/icvgip18/"><em>ICVGIP</em></a>, ACM, 2018 &nbsp <font color="red">(Oral)</font>
              <br>

                <div class="paper" id="aecnn">
                <a href="javascript:toggleblock('aecnnabs')"><font color="red">abstract</font></a> / 
                <a shape="rect" href="javascript:togglebib('aecnn')" class="togglebib"><font color="red">bibtex</font></a> / 
                <a href="https://dl.acm.org/doi/abs/10.1145/3293353.3293408" target="_blank"><font color="red">proceedings</font></a> /
                <a href="https://github.com/ekagra-ranjan/AE-CNN" target="_blank"><font color="red">Code</font></a> / 
                <a href="pubs/Paper55.pptx"><font color="red">slides</font></a>
                <br>

                <p align="justify"> <i id="aecnnabs">Deep learning models trained in natural images are commonly used for different classification tasks in the 
                medical domain. Generally, very high dimensional medical images are down-sampled by using interpolation techniques before feeding them to deep 
                learning models that are ImageNet compliant and accept only low-resolution images of size 224 x 224 px. This popular technique may lead to the 
                loss of key information thus hampering the classification. Significant pathological features in medical images typically being small sized and 
                highly affected. To combat this problem, we introduce a convolutional neural network (CNN) based classification approach which learns to reduce 
                the resolution of the image using an autoencoder and at the same time classify it using another network, while both the tasks are trained jointly. 
                This algorithm guides the model to learn essential representations from high-resolution images for classification along with reconstruction. We 
                have used the publicly available dataset of chest x-rays to evaluate this approach and have outperformed state-of-the-art on test data. Besides, 
                we have experimented with the effects of different augmentation approaches in this dataset and report baselines using some well known ImageNet 
                class of CNNs.</i></p>

      <pre xml:space="preserve">
      @inproceedings{ranjan2018jointly,
        title={Jointly learning convolutional representations to compress radiological images and classify thoracic diseases in the compressed domain},
        author={Ranjan, Ekagra and Paul, Soumava and Kapoor, Siddharth and Kar, Aupendu and Sethuraman, Ramanathan and Sheet, Debdoot},
        booktitle={Proceedings of the 11th Indian Conference on computer vision, graphics and image processing},
        pages={1--8},
        year={2018}
      }
      }</pre>
              </div>
            </td>
        </tr>
      </table>

      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr><td style="padding:10px;width:100%;vertical-align:middle">
          <heading>Side Hustles</heading>
        </td></tr>
      </tbody></table>
      
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr>
          <td style="padding:20px;width:25%;vertical-align:middle">
            <img src="RC/files/rc_480x310_samples1000_envdof.png" width=300 height=194 style="border-style: none">
          </td>
            <td width="67%" valign="top">
              <papertitle>Four Musings and a Mural</papertitle><br>
              <strong>Soumava Paul</strong>, <a href="https://github.com/nilkel" target="_blank">Neel Kelkar</a>
              <br>
              <div class="paper" id="RC">
                <a href="RC/home.html" target="_blank"><font color="red">project page</font></a> /
                <a href="https://github.com/mvp18/ray-tracer" target="_blank"><font color="red">Code</font></a>
                <br>

                <p align="justify"> <i id="RCabs">Our submission for the 
                  <a href="https://graphics.cg.uni-saarland.de/courses/cg1-2022/index.html#rendering-competition" target="_blank">Rendering Competiton</a> of the 
                  <a href="https://graphics.cg.uni-saarland.de/courses/cg1-2022/index.html" target="_blank">Computer Graphics-I</a> course at UdS (Winter Term 2022/23).
                  Finished in the A-tier with 80% points, narrowly missing out on the podium places.</i></p>
              </div>
          </td>
        </tr>
      </table>

      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr>
          <td style="padding:20px;width:25%;vertical-align:middle">
            <img src="images/armyo.png" width=300 height=311 style="border-style: none">
          </td>
            <td width="67%" valign="top">
              <papertitle>ArMyo</papertitle><br>
              LBS Hall (IIT Kgp) Hardware Modelling Team
              <br>
              <div class="paper" id="HaMo2019">
                <a href="data/HaMo-Report-2019.pdf" target="_blank"><font color="red">Report</font></a> /
                <a href="https://github.com/mvp18/ArMyo" target="_blank"><font color="red">Code</font></a>
                <br>

                <p align="justify"> <i id="HaMo2019abs">Our submission for the Inter-Hall Hardware Modelling Competiton at IIT Kgp in 2019. We built a robotic 
                  exoskeleton system for assisting patients with muscular atrophy. Secured <strong>4<sup>th</sup></strong> place out of 15 teams.</i></p>
              </div>
          </td>
        </tr>
      </table>

      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="5">
        <tr>
          <td width="75%" valign="center" id="Service">
            <sectionheading>&nbsp;&nbsp;Academic Service</sectionheading>
            <ul>
              <li>Technical Reviewer for <a href="https://nips.cc/" target="_blank">Neurips 2023</a>, <a href="https://sites.google.com/view/ecv23" target="_blank">CVPR-W 2023</a></li>
            </ul>
          </td>
        </tr>
      </table>
        
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="5">
        <tr>
          <td width="75%" valign="center" id="Teaching">
            <sectionheading>&nbsp;&nbsp;Teaching</sectionheading>
            <ul>
              <li>Tutor, <a href="https://www.mia.uni-saarland.de/Teaching/dic23.shtml" target="_blank">Differential Equations in Image Processing and Computer Vision </a>
              (Winter Term 2023-24) by <a href="https://www.mia.uni-saarland.de/peter/index.shtml" target="_blank">Dr. Pascal Peter (UdS)</a></li>
              <li>Teaching Assistant, <a href="https://www.mpi-inf.mpg.de/departments/computer-vision-and-machine-learning/teaching/courses-1/ss-2023-high-level-computer-vision" target="_blank">High-Level Computer Vision</a> 
                (Summer Term 2023) 
                by <a href="https://www.mpi-inf.mpg.de/departments/computer-vision-and-machine-learning/people/bernt-schiele" target="_blank">Prof. Dr. Bernt Schiele (MPII)</a></li>
              <li>Tutor, <a href="https://www.mia.uni-saarland.de/Teaching/ipcv23.shtml" target="_blank">Image Processing and Computer Vision</a> (Summer Term 2023) 
                by <a href="https://www.mia.uni-saarland.de/peter/index.shtml" target="_blank">Dr. Pascal Peter (UdS)</a></li>
            </ul>
          </td>
        </tr>
      </table>

      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="5">
        <tr><td width="75%" valign="center" id="Misc">
            <sectionheading>&nbsp;&nbsp;Misc</sectionheading>
            <ul>
            <li>In my downtime, I like to play tennis, pingpong, and football. I have played tennis for more than 15 years and translate my racquet skills to be half-decent
              at pingpong. I also bike sometimes around the hills of Saarbrücken.</li>
            <li>I speak English, Bengali, and Hindi natively und ich spreche ein bisschen Deutsch.</li>
            <li>On weekends, I follow the <a href="https://www.youtube.com/watch?v=mIR3mTrjLOI" target="_blank">English Premier League</a> and overthink which players to pick for my 
              <a href="https://fantasy.premierleague.com/entry/254432/history" target="_blank">fantasy football team</a>. My favorite footballers of all-time
              are <a href="https://www.youtube.com/watch?v=C-CefuZ6h1k" target="_blank">Son Heung-min</a> and <a href="https://www.youtube.com/watch?v=RDsxKXa0PbA" target="_blank">Zlatan Ibrahimović</a>.
            </li>
            <li>I have watched <a href="https://www.youtube.com/@TheOffice" target="_blank">The Office (US)</a> at least 10 times, back and forth.</li>
            <li>I use <strong>mvp18</strong> as my web handle for social accounts, a nickname I came up with when I turned (you guessed it) 18! I had just cracked
            <a href="https://www.quora.com/Is-IIT-JEE-the-toughest-exam-in-the-world-What-would-it-be-ranked" target="_blank">IIT-JEE</a> and felt like a real hotshot back then. The next 4 years couldn't have been any more humbling :')</li>
            <li>In an earlier life, I could <a href="data/deception.pdf">write</a>.</li>
            </ul>
        </td></tr>
      </table>

      This revolver map seemed kinda cool. It shows total webpage visits since April 13, 2023.
      <br>
      <script type="text/javascript" src="//rf.revolvermaps.com/0/0/8.js?i=5lfhuqxvm76&amp;m=7&amp;c=00ff6c&amp;cr1=ff0000&amp;f=verdana&amp;l=33&amp;bv=60" async="async"></script>

      <!-- <div style="width:200px; pointer-events: none;">
        <script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=043361&w=153&t=n&d=l3lesztPwCz-uXlzFI1Lt9SB3Ctz-pBQuMdYqnD0Ul8&co=ffffff&cmo=3eb7f0&ct=043361'></script>
      </div> -->

      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
          <td style="padding:0px">
            <br>
            <p style="text-align:right;font-size:small;">
              <a href="https://jonbarron.info/" target="_blank">Imitation is the most sincere form of flattery</a>
            </p>
          </td>
        </tr>
      </tbody></table>

    </td></tr>
  </table>
<script xml:space="preserve" language="JavaScript">
hideallbibs();
</script>
<script xml:space="preserve" language="JavaScript">
hideblock('ucdrabs');
</script>
<script xml:space="preserve" language="JavaScript">
hideblock('kdsvdabs');
</script>
<script xml:space="preserve" language="JavaScript">
hideblock('gALabs');
</script>
<script xml:space="preserve" language="JavaScript">
hideblock('aecnnabs');
</script>
<script xml:space="preserve" language="JavaScript">
hideblock('ttt-ucdrabs');
</script>

</body>

</html>